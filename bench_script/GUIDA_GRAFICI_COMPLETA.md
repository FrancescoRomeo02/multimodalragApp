# ðŸ“Š GUIDA COMPLETA AI GRAFICI DI ANALISI RAG

Questa guida spiega tutti i grafici generati dal sistema di analisi delle performance del modello RAG locale rispetto a Morphik. Ogni grafico Ã¨ ora salvato in un file separato per una migliore organizzazione e consultazione.

---

## ðŸ“ˆ GRAFICI DI PERFORMANCE GENERALE

### ðŸ“Š `01_performance_per_difficolta.png` - Performance per Livello di DifficoltÃ 
- **Scopo**: Mostra come la performance del modello varia con la difficoltÃ  delle domande (1=facile â†’ 10=difficile)
- **Cosa osservare**: 
  - Trend generale: il modello dovrebbe performance meglio su domande facili
  - Valori anomali: difficoltÃ  medie che performano meglio di quelle facili
  - Deviazione standard: indica la consistenza del modello per ogni livello
- **Interpretazione**: Barre piÃ¹ alte = migliore performance. Errori piÃ¹ piccoli = maggiore consistenza.

### ðŸ“Š `02_performance_per_argomento.png` - Performance per Macro-Argomento  
- **Scopo**: Identifica gli argomenti su cui il modello eccelle o fallisce
- **Categorie**: Energia, Tecnologia, Geografia, Matematica, Ambiente, Ingegneria, Economia, Fisica, Generale
- **Cosa osservare**:
  - Argomenti piÃ¹ problematici (barre corte)
  - Argomenti di forza del modello (barre lunghe)
  - Numero di domande per argomento (n=X)
- **Interpretazione**: Aiuta a identificare domini di conoscenza da potenziare.

### ðŸ“Š `03_heatmap_argomento_difficolta.png` - Heatmap DifficoltÃ  vs Macro-Argomento
- **Scopo**: Visualizza l'interazione tra difficoltÃ  e argomento
- **Colori**: Verde = buona performance, Rosso = performance scarsa
- **Cosa osservare**:
  - Celle rosse: combinazioni problematiche difficoltÃ -argomento
  - Celle verdi: combinazioni di successo
  - Pattern diagonali o specifici
- **Interpretazione**: Identifica se certi argomenti sono difficili solo ad alti livelli di difficoltÃ .

### ðŸ“Š `04_distribuzione_performance.png` - Distribuzione Performance Globale
- **Scopo**: Mostra la distribuzione complessiva delle performance con soglie di qualitÃ 
- **Linee di riferimento**:
  - Verde: Soglia eccellente (â‰¥0.85)
  - Arancione: Soglia buona (â‰¥0.70)  
  - Rossa: Soglia critica (â‰¥0.30)
  - Blu: Media del sistema
- **Interpretazione**: Forma della distribuzione indica se il modello Ã¨ consistente o ha performance bimodali.

---

## ðŸ”¬ GRAFICI DI ANALISI DETTAGLIATA

### ðŸ“Š `05_correlazione_chunk_performance.png` - Correlazione QualitÃ  Retrieval vs Performance
- **Scopo**: Valuta se un migliore retrieval dei chunk porta a migliori risposte
- **Assi**: X = F1 Score del retrieval, Y = SimilaritÃ  semantica della risposta
- **Linea rossa**: Tendenza di correlazione
- **Cosa osservare**:
  - Correlazione positiva forte: buon retrieval â†’ buone risposte
  - Punti lontani dalla linea: casi anomali da investigare
  - Valore di correlazione mostrato
- **Interpretazione**: Alta correlazione indica che il problema Ã¨ nel retrieval, bassa correlazione indica problemi nella generazione.

### ðŸ“Š `06_lunghezza_per_qualita.png` - Rapporto Lunghezza per QualitÃ  Risposta
- **Scopo**: Analizza se risposte piÃ¹ lunghe/corte sono associate a migliore/peggiore qualitÃ 
- **Categorie**: Molto Scarso, Scarso, Accettabile, Buono, Eccellente
- **Boxplot**: Mostra distribuzione dei rapporti di lunghezza per ogni categoria
- **Cosa osservare**:
  - Mediana intorno a 1.0 = lunghezza simile a Morphik
  - Valori > 1.5 = risposte troppo prolisse
  - Valori < 0.5 = risposte troppo brevi
- **Interpretazione**: Aiuta a calibrare la lunghezza ideale delle risposte.

### ðŸ“Š `07_performance_per_tipo_domanda.png` - Performance per Tipo di Domanda
- **Scopo**: Identifica tipologie di domande problematiche
- **Tipi**: Definitoria, Comparativa, Procedurale, Analitica, Enumerativa, Altra
- **Cosa osservare**:
  - Tipi con performance basse
  - Numero di domande per tipo
  - VariabilitÃ  all'interno del tipo
- **Interpretazione**: Suggerisce strategie di prompting specifiche per tipo.

### ðŸ“Š `08_coverage_termini_tecnici.png` - Coverage Termini Tecnici per Argomento
### ðŸ“Š `08_coverage_termini_tecnici.png` - Coverage Termini Tecnici per Argomento
- **Scopo**: Valuta se il modello usa la terminologia tecnica appropriata
- **Metrica**: Rapporto tra termini tecnici nella risposta locale vs Morphik
- **Cosa osservare**:
  - Argomenti con bassa coverage tecnica
  - VariabilitÃ  (errori grandi = inconsistenza)
  - Valori > 1.0 = uso eccessivo di termini tecnici
- **Interpretazione**: Indica se il modello manca di precisione terminologica.

---

## ðŸš¨ GRAFICI DI ANALISI CASI CRITICI

### ðŸ“Š `09_casi_non_risposta.png` - Casi di Non-Risposta  
- **Scopo**: Identifica quando il modello non riesce a fornire alcuna risposta (similaritÃ  = 0)
- **Visualizzazione**: Conteggio per macro-argomento dei casi di fallimento totale
- **Cosa osservare**:
  - Argomenti dove il modello fallisce completamente
  - Pattern di non-risposta per identificare problemi strutturali
  - Volume totale di fallimenti
- **Interpretazione**: Indica problemi critici nel retrieval o nella generazione che impediscono qualsiasi output.

### ðŸ“Š `10_peggiori_performance.png` - Peggiori Performance Effettive
- **Scopo**: Identifica i casi con le performance piÃ¹ basse tra quelli che hanno effettivamente risposto
- **Esclusioni**: Non include i casi di non-risposta (similaritÃ  = 0)
- **Cosa osservare**:
  - Performance molto basse ma non nulle
  - Pattern comuni nelle risposte scadenti
  - Confronto con soglie di accettabilitÃ 
- **Interpretazione**: Mostra dove il modello risponde ma con qualitÃ  molto scarsa, suggerendo problemi di generazione piuttosto che retrieval.

### ðŸ“Š `11_distribuzione_per_difficolta.png` - Distribuzione per DifficoltÃ 
- **Scopo**: Boxplot che mostra la variabilitÃ  per categoria di difficoltÃ 
- **Categorie**: Facile (1-3), Media (4-7), Difficile (8-10)
- **Cosa osservare**:
  - Mediane decrescenti con difficoltÃ 
  - Outliers (punti esterni ai box)
  - Sovrapposizione tra categorie
- **Interpretazione**: Valuta se la classificazione di difficoltÃ  Ã¨ significativa e se il modello gestisce adeguatamente la complessitÃ .

---

## ðŸ“„ GRAFICI DI ANALISI PER DOCUMENTO

*Generati solo se ci sono piÃ¹ documenti*

### ðŸ“Š `12_performance_per_paper.png` - Performance per Paper/Documento
- **Scopo**: Confronta la performance del modello su diversi documenti
- **Cosa osservare**:
  - Documenti particolarmente problematici
  - VariabilitÃ  tra documenti
  - Numero di domande per documento
- **Interpretazione**: Alcuni documenti potrebbero essere piÃ¹ difficili da processare.

### ðŸ“Š `13_variabilita_per_paper.png` - VariabilitÃ  Performance per Paper
- **Scopo**: Boxplot della consistenza all'interno di ogni documento
- **Cosa osservare**:
  - Box larghi = alta variabilitÃ  interna
  - Box stretti = performance consistente
  - Outliers all'interno dei documenti
- **Interpretazione**: Indica se alcuni documenti hanno sezioni piÃ¹ difficili.

---

## ðŸŽ¯ COME UTILIZZARE I GRAFICI

### 1. **Workflow di Analisi Consigliato**:
   1. **Inizia con i grafici di performance generale** (01-04) per avere un quadro d'insieme
   2. **Approfondisci con l'analisi dettagliata** (05-08) per identificare le cause specifiche
   3. **Esamina i casi critici** (09-11) per comprendere i fallimenti
   4. **Se hai multipli documenti**, consulta i grafici per documento (12-13)

### 2. **Ordine di Consultazione Raccomandato**:
   - `04_distribuzione_performance.png` â†’ Overview generale del sistema
   - `01_performance_per_difficolta.png` â†’ Verifica gestione della complessitÃ 
   - `02_performance_per_argomento.png` â†’ Identifica domini problematici
   - `05_correlazione_chunk_performance.png` â†’ Diagnosi retrieval vs generazione
   - `09_casi_non_risposta.png` â†’ Identifica fallimenti critici
   - `07_performance_per_tipo_domanda.png` â†’ Strategie di miglioramento

### 3. **Indicatori di Alert**:
   - **ðŸ”´ Alert Rosso**: SimilaritÃ  media < 0.30 in qualsiasi categoria
   - **ðŸŸ¡ Alert Giallo**: SimilaritÃ  media < 0.50 in categorie principali  
   - **âœ… Target**: SimilaritÃ  media > 0.70 in tutte le categorie
   - **ðŸ† Eccellenza**: SimilaritÃ  media > 0.85

---

## ðŸš¨ DASHBOARD 3: Analisi Casi Critici (`critical_cases_analysis.png`)

### Grafico 1: Casi di Non-Risposta  
- **Scopo**: Identifica quando il modello non riesce a fornire alcuna risposta (similaritÃ  = 0)
- **Visualizzazione**: Conteggio per macro-argomento dei casi di fallimento totale
- **Cosa osservare**:
  - Argomenti dove il modello fallisce completamente
  - Pattern di non-risposta per identificare problemi strutturali
  - Volume totale di fallimenti
- **Interpretazione**: Indica problemi critici nel retrieval o nella generazione che impediscono qualsiasi output.

### Grafico 2: Peggiori Performance Effettive
- **Scopo**: Identifica i casi con le performance piÃ¹ basse tra quelli che hanno effettivamente risposto
- **Esclusioni**: Non include i casi di non-risposta (similaritÃ  = 0)
- **Cosa osservare**:
  - Performance molto basse ma non nulle
  - Pattern comuni nelle risposte scadenti
  - Confronto con soglie di accettabilitÃ 
- **Interpretazione**: Mostra dove il modello risponde ma con qualitÃ  molto scarsa, suggerendo problemi di generazione piuttosto che retrieval.

### Grafico 3: Distribuzione per DifficoltÃ 
- **Scopo**: Boxplot che mostra la variabilitÃ  per categoria di difficoltÃ 
- **Categorie**: Facile (1-3), Media (4-7), Difficile (8-10)
- **Cosa osservare**:
  - Mediane decrescenti con difficoltÃ 
  - Outliers (punti esterni ai box)
  - Sovrapposizione tra categorie
- **Interpretazione**: Valuta se la classificazione di difficoltÃ  Ã¨ significativa e se il modello gestisce adeguatamente la complessitÃ .

---

## ðŸ“„ DASHBOARD 4: Analisi per Documento (`paper_analysis.png`)

*Generata solo se ci sono piÃ¹ documenti*

### Grafico 1: Performance per Paper/Documento
- **Scopo**: Confronta la performance del modello su diversi documenti
- **Cosa osservare**:
  - Documenti particolarmente problematici
  - VariabilitÃ  tra documenti
  - Numero di domande per documento
- **Interpretazione**: Alcuni documenti potrebbero essere piÃ¹ difficili da processare.

### Grafico 2: VariabilitÃ  Performance per Paper
- **Scopo**: Boxplot della consistenza all'interno di ogni documento
- **Cosa osservare**:
  - Box larghi = alta variabilitÃ  interna
  - Box stretti = performance consistente
  - Outliers all'interno dei documenti
- **Interpretazione**: Indica se alcuni documenti hanno sezioni piÃ¹ difficili.

---

## ðŸŽ¯ COME UTILIZZARE I GRAFICI

### 1. **Workflow di Analisi Consigliato**:
   1. Inizia con Dashboard 1 per overview generale
   2. Usa Dashboard 2 per analisi dettagliata delle cause
   3. Esamina Dashboard 3 per casi specifici
   4. Se multipli documenti, consulta Dashboard 4

### 2. **Indicatori di Alert**:
   - **ðŸ”´ Alert Rosso**: SimilaritÃ  media < 0.30 in qualsiasi categoria
   - **ðŸŸ¡ Alert Giallo**: SimilaritÃ  media < 0.50 in categorie principali  
   - **âœ… Target**: SimilaritÃ  media > 0.70 in tutte le categorie
   - **ðŸ† Eccellenza**: SimilaritÃ  media > 0.85

### 4. **Pattern da Investigare**:
   - **Correlazione retrieval-performance bassa**: Problema nella generazione
   - **Performance peggiore su difficoltÃ  alte**: Normale, ma verifica il gap
   - **Argomenti specifici problematici**: Mancanza di knowledge domain
   - **Alta variabilitÃ **: Modello inconsistente, serve regularization

### 5. **Azioni Raccomandate per Categoria**:
   - **Retrieval**: Migliorare chunking, embedding, ranking
   - **Generazione**: Ottimizzare prompt, temperatura, max_tokens
   - **Knowledge**: Aggiungere documenti specifici per argomenti deboli
   - **Consistency**: Implementare ensemble methods o post-processing

---

## ðŸ“‹ CHECKLIST DI CONTROLLO QUALITÃ€

**âœ… Sistema Sano**:
- [ ] SimilaritÃ  media > 0.60 (`04_distribuzione_performance.png`)
- [ ] Tasso Buono+ > 50% (verificare nel report)
- [ ] Correlazione retrieval-performance > 0.4 (`05_correlazione_chunk_performance.png`)
- [ ] Nessun argomento con similaritÃ  < 0.30 (`02_performance_per_argomento.png`)
- [ ] Pochi o zero casi di non-risposta (`09_casi_non_risposta.png`)

**âš ï¸ Sistema che Necessita Attenzione**:
- [ ] SimilaritÃ  media 0.40-0.60
- [ ] Tasso Buono+ 30-50% 
- [ ] Alcuni argomenti problematici
- [ ] Alta variabilitÃ  tra documenti (`13_variabilita_per_paper.png`)

**ðŸš¨ Sistema Critico**:
- [ ] SimilaritÃ  media < 0.40
- [ ] Tasso Buono+ < 30%
- [ ] Molti casi con similaritÃ  = 0 (`09_casi_non_risposta.png`)
- [ ] Nessuna correlazione retrieval-performance (`05_correlazione_chunk_performance.png`)

---

## ðŸ“ STRUTTURA FILE GENERATI

```
plots/
â”œâ”€â”€ 01_performance_per_difficolta.png      # Performance vs difficoltÃ 
â”œâ”€â”€ 02_performance_per_argomento.png       # Performance per argomento
â”œâ”€â”€ 03_heatmap_argomento_difficolta.png    # Interazione difficoltÃ -argomento
â”œâ”€â”€ 04_distribuzione_performance.png       # Distribuzione generale
â”œâ”€â”€ 05_correlazione_chunk_performance.png  # Correlazione retrieval-risposta
â”œâ”€â”€ 06_lunghezza_per_qualita.png          # Analisi lunghezza risposte
â”œâ”€â”€ 07_performance_per_tipo_domanda.png    # Performance per tipo domanda
â”œâ”€â”€ 08_coverage_termini_tecnici.png       # Coverage terminologia
â”œâ”€â”€ 09_casi_non_risposta.png              # Fallimenti totali
â”œâ”€â”€ 10_peggiori_performance.png           # Peggiori performance effettive
â”œâ”€â”€ 11_distribuzione_per_difficolta.png   # Boxplot per difficoltÃ 
â”œâ”€â”€ 12_performance_per_paper.png          # Performance per documento*
â””â”€â”€ 13_variabilita_per_paper.png          # VariabilitÃ  per documento*

* = Generati solo con piÃ¹ documenti
```

---

*Documentazione aggiornata per il sistema di analisi RAG con grafici separati*
