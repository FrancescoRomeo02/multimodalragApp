# ===========================
# MULTIMODAL RAG CONFIGURATION
# ===========================

# ðŸš¨ IMPORTANTE: Copia questo file come .env e configura GROQ_API_KEY
# cp .env.example .env

# ===========================
# API KEYS (OBBLIGATORIE)
# ===========================

# Groq API per LLM (OBBLIGATORIA)
# Ottieni la tua chiave da: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# OpenAI API per embedding (opzionale, se usi modelli OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# ===========================
# DATABASE CONFIGURATION
# ===========================

# URL del server Qdrant (locale o remoto)
QDRANT_URL=http://localhost:6333

# Nome della collezione Qdrant
COLLECTION_NAME=papers_custom_pipeline

# ===========================
# LLM CONFIGURATION
# ===========================

# Modello LLM da utilizzare (disponibili su Groq)
LLM_MODEL_NAME=llama3-8b-8192

# ===========================
# LOGGING
# ===========================

# Livello di logging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Directory per i file di log
LOG_DIR=logs

# ===========================
# PROCESSING CONFIGURATION
# ===========================

# Dimensione massima file PDF (in MB)
MAX_FILE_SIZE_MB=50

# Numero massimo di pagine da processare per PDF
MAX_PAGES_PER_PDF=100

# Directory temporanea per processing
TEMP_DIR=temp

# ===========================
# ISTRUZIONI RAPIDE
# ===========================

# ðŸŽ¯ PER DOCENTI/VALUTATORI:
# 1. cp .env.example .env
# 2. Modifica GROQ_API_KEY nel file .env
# 3. docker-compose up -d
# 4. Apri http://localhost:8501

# ðŸ”§ PER SVILUPPATORI:
# 1. cp .env.example .env
# 2. Configura tutte le variabili necessarie
# 3. make setup-dev
# 4. make run

# ===========================
# TROUBLESHOOTING
# ===========================

# Porta giÃ  in uso? Cambia porta Streamlit:
# STREAMLIT_PORT=8502

# Problemi memoria? Riduci batch size:
# DEFAULT_BATCH_SIZE=16

# Debug? Abilita logging dettagliato:
# LOG_LEVEL=DEBUG
