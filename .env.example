# ===========================
# MULTIMODAL RAG CONFIGURATION
# ===========================

# Copia questo file come .env e inserisci i valori reali

# ===========================
# API KEYS (OBBLIGATORIE)
# ===========================

# Groq API per LLM (richiesta)
GROQ_API_KEY=your_groq_api_key_here

# OpenAI API per embedding (opzionale, se usi modelli OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# ===========================
# DATABASE CONFIGURATION
# ===========================

# URL del server Qdrant (locale o remoto)
QDRANT_URL=http://localhost:6333

# Nome della collezione Qdrant
COLLECTION_NAME=papers_custom_pipeline

# ===========================
# LLM CONFIGURATION
# ===========================

# Modello LLM da utilizzare (disponibili su Groq)
LLM_MODEL_NAME=meta-llama/llama-3-8b-instruct

# ===========================
# LOGGING
# ===========================

# Livello di logging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Directory per i file di log
LOG_DIR=logs

# ===========================
# PROCESSING CONFIGURATION
# ===========================

# Dimensione massima file PDF (in MB)
MAX_FILE_SIZE_MB=50

# Numero massimo di pagine da processare per PDF
MAX_PAGES_PER_PDF=100

# Directory temporanea per processing
TEMP_DIR=temp
