# üìä GUIDA COMPLETA AI GRAFICI DI ANALISI RAG

Questa guida spiega tutti i grafici generati dal sistema di analisi delle performance del modello RAG locale rispetto a Morphik. Ogni grafico √® ora salvato in un file separato per una migliore organizzazione e consultazione.

---

## GRAFICI DI PERFORMANCE GENERALE

### `01_performance_per_difficolta.png` - Performance per Livello di Difficolt√†
- **Scopo**: Mostra come la performance del modello varia con la difficolt√† delle domande (1=facile ‚Üí 10=difficile)
- **Cosa osservare**: 
  - Trend generale: il modello dovrebbe performance meglio su domande facili
  - Valori anomali: difficolt√† medie che performano meglio di quelle facili
  - Deviazione standard: indica la consistenza del modello per ogni livello
- **Interpretazione**: Barre pi√π alte = migliore performance. Errori pi√π piccoli = maggiore consistenza.

### `02_performance_per_argomento.png` - Performance per Macro-Argomento  
- **Scopo**: Identifica gli argomenti su cui il modello eccelle o fallisce
- **Categorie**: Energia, Tecnologia, Geografia, Matematica, Ambiente, Ingegneria, Economia, Fisica, Generale
- **Cosa osservare**:
  - Argomenti pi√π problematici (barre corte)
  - Argomenti di forza del modello (barre lunghe)
  - Numero di domande per argomento (n=X)
- **Interpretazione**: Aiuta a identificare domini di conoscenza da potenziare.

### `03_heatmap_argomento_difficolta.png` - Heatmap Difficolt√† vs Macro-Argomento
- **Scopo**: Visualizza l'interazione tra difficolt√† e argomento
- **Colori**: Verde = buona performance, Rosso = performance scarsa
- **Cosa osservare**:
  - Celle rosse: combinazioni problematiche difficolt√†-argomento
  - Celle verdi: combinazioni di successo
  - Pattern diagonali o specifici
- **Interpretazione**: Identifica se certi argomenti sono difficili solo ad alti livelli di difficolt√†.

### `04_distribuzione_performance.png` - Distribuzione Performance Globale
- **Scopo**: Mostra la distribuzione complessiva delle performance con soglie di qualit√†
- **Linee di riferimento**:
  - Verde: Soglia eccellente (‚â•0.85)
  - Arancione: Soglia buona (‚â•0.70)  
  - Rossa: Soglia critica (‚â•0.30)
  - Blu: Media del sistema
- **Interpretazione**: Forma della distribuzione indica se il modello √® consistente o ha performance bimodali.

---

## GRAFICI DI ANALISI DETTAGLIATA

### `05_correlazione_chunk_performance.png` - Correlazione Qualit√† Retrieval vs Performance
- **Scopo**: Valuta se un migliore retrieval dei chunk porta a migliori risposte
- **Assi**: X = F1 Score del retrieval, Y = Similarit√† semantica della risposta
- **Linea rossa**: Tendenza di correlazione
- **Cosa osservare**:
  - Correlazione positiva forte: buon retrieval ‚Üí buone risposte
  - Punti lontani dalla linea: casi anomali da investigare
  - Valore di correlazione mostrato
- **Interpretazione**: Alta correlazione indica che il problema √® nel retrieval, bassa correlazione indica problemi nella generazione.

### `06_lunghezza_per_qualita.png` - Rapporto Lunghezza per Qualit√† Risposta
- **Scopo**: Analizza se risposte pi√π lunghe/corte sono associate a migliore/peggiore qualit√†
- **Categorie**: Molto Scarso, Scarso, Accettabile, Buono, Eccellente
- **Boxplot**: Mostra distribuzione dei rapporti di lunghezza per ogni categoria
- **Cosa osservare**:
  - Mediana intorno a 1.0 = lunghezza simile a Morphik
  - Valori > 1.5 = risposte troppo prolisse
  - Valori < 0.5 = risposte troppo brevi
- **Interpretazione**: Aiuta a calibrare la lunghezza ideale delle risposte.

### `07_performance_per_tipo_domanda.png` - Performance per Tipo di Domanda
- **Scopo**: Identifica tipologie di domande problematiche
- **Tipi**: Definitoria, Comparativa, Procedurale, Analitica, Enumerativa, Altra
- **Cosa osservare**:
  - Tipi con performance basse
  - Numero di domande per tipo
  - Variabilit√† all'interno del tipo
- **Interpretazione**: Suggerisce strategie di prompting specifiche per tipo.

### `08_coverage_termini_tecnici.png` - Coverage Termini Tecnici per Argomento
- **Scopo**: Valuta se il modello usa la terminologia tecnica appropriata
- **Metrica**: Rapporto tra termini tecnici nella risposta locale vs Morphik
- **Cosa osservare**:
  - Argomenti con bassa coverage tecnica
  - Variabilit√† (errori grandi = inconsistenza)
  - Valori > 1.0 = uso eccessivo di termini tecnici
- **Interpretazione**: Indica se il modello manca di precisione terminologica.

---

## GRAFICI DI ANALISI CASI CRITICI

### `09_casi_non_risposta.png` - Casi di Non-Risposta
- **Scopo**: Identifica quando il modello non riesce a fornire alcuna risposta (similarit√† = 0)
- **Visualizzazione**: Conteggio per macro-argomento dei casi di fallimento totale
- **Cosa osservare**:
  - Argomenti dove il modello fallisce completamente
  - Pattern di non-risposta per identificare problemi strutturali
  - Volume totale di fallimenti
- **Interpretazione**: Indica problemi critici nel retrieval o nella generazione che impediscono qualsiasi output.

### `10_peggiori_performance.png` - Peggiori Performance Effettive
- **Scopo**: Identifica i casi con le performance pi√π basse tra quelli che hanno effettivamente risposto
- **Esclusioni**: Non include i casi di non-risposta (similarit√† = 0)
- **Cosa osservare**:
  - Performance molto basse ma non nulle
  - Pattern comuni nelle risposte scadenti
  - Confronto con soglie di accettabilit√†
- **Interpretazione**: Mostra dove il modello risponde ma con qualit√† molto scarsa, suggerendo problemi di generazione piuttosto che retrieval.

### `11_distribuzione_per_difficolta.png` - Distribuzione per Difficolt√†
- **Scopo**: Boxplot che mostra la variabilit√† per categoria di difficolt√†
- **Categorie**: Facile (1-3), Media (4-7), Difficile (8-10)
- **Cosa osservare**:
  - Mediane decrescenti con difficolt√†
  - Outliers (punti esterni ai box)
  - Sovrapposizione tra categorie
- **Interpretazione**: Valuta se la classificazione di difficolt√† √® significativa e se il modello gestisce adeguatamente la complessit√†.

---

## üìÑ GRAFICI DI ANALISI PER DOCUMENTO

*Generati solo se ci sono pi√π documenti*

### üìä `12_performance_per_paper.png` - Performance per Paper/Documento
- **Scopo**: Confronta la performance del modello su diversi documenti
- **Cosa osservare**:
  - Documenti particolarmente problematici
  - Variabilit√† tra documenti
  - Numero di domande per documento
- **Interpretazione**: Alcuni documenti potrebbero essere pi√π difficili da processare.

### üìä `13_variabilita_per_paper.png` - Variabilit√† Performance per Paper
- **Scopo**: Boxplot della consistenza all'interno di ogni documento
- **Cosa osservare**:
  - Box larghi = alta variabilit√† interna
  - Box stretti = performance consistente
  - Outliers all'interno dei documenti
- **Interpretazione**: Indica se alcuni documenti hanno sezioni pi√π difficili.

---

## üéØ COME UTILIZZARE I GRAFICI

### 1. **Workflow di Analisi Consigliato**:
   1. **Inizia con i grafici di performance generale** (01-04) per avere un quadro d'insieme
   2. **Approfondisci con l'analisi dettagliata** (05-08) per identificare le cause specifiche
   3. **Esamina i casi critici** (09-11) per comprendere i fallimenti
   4. **Se hai multipli documenti**, consulta i grafici per documento (12-13)

### 2. **Ordine di Consultazione Raccomandato**:
   - `04_distribuzione_performance.png` ‚Üí Overview generale del sistema
   - `01_performance_per_difficolta.png` ‚Üí Verifica gestione della complessit√†
   - `02_performance_per_argomento.png` ‚Üí Identifica domini problematici
   - `05_correlazione_chunk_performance.png` ‚Üí Diagnosi retrieval vs generazione
   - `09_casi_non_risposta.png` ‚Üí Identifica fallimenti critici
   - `07_performance_per_tipo_domanda.png` ‚Üí Strategie di miglioramento

### 3. **Indicatori di Alert**:
   - **üî¥ Alert Rosso**: Similarit√† media < 0.30 in qualsiasi categoria
   - **üü° Alert Giallo**: Similarit√† media < 0.50 in categorie principali  
   - **‚úÖ Target**: Similarit√† media > 0.70 in tutte le categorie
   - **üèÜ Eccellenza**: Similarit√† media > 0.85

---

## üö® DASHBOARD 3: Analisi Casi Critici (`critical_cases_analysis.png`)

### Grafico 1: Casi di Non-Risposta  
- **Scopo**: Identifica quando il modello non riesce a fornire alcuna risposta (similarit√† = 0)
- **Visualizzazione**: Conteggio per macro-argomento dei casi di fallimento totale
- **Cosa osservare**:
  - Argomenti dove il modello fallisce completamente
  - Pattern di non-risposta per identificare problemi strutturali
  - Volume totale di fallimenti
- **Interpretazione**: Indica problemi critici nel retrieval o nella generazione che impediscono qualsiasi output.

### Grafico 2: Peggiori Performance Effettive
- **Scopo**: Identifica i casi con le performance pi√π basse tra quelli che hanno effettivamente risposto
- **Esclusioni**: Non include i casi di non-risposta (similarit√† = 0)
- **Cosa osservare**:
  - Performance molto basse ma non nulle
  - Pattern comuni nelle risposte scadenti
  - Confronto con soglie di accettabilit√†
- **Interpretazione**: Mostra dove il modello risponde ma con qualit√† molto scarsa, suggerendo problemi di generazione piuttosto che retrieval.

### Grafico 3: Distribuzione per Difficolt√†
- **Scopo**: Boxplot che mostra la variabilit√† per categoria di difficolt√†
- **Categorie**: Facile (1-3), Media (4-7), Difficile (8-10)
- **Cosa osservare**:
  - Mediane decrescenti con difficolt√†
  - Outliers (punti esterni ai box)
  - Sovrapposizione tra categorie
- **Interpretazione**: Valuta se la classificazione di difficolt√† √® significativa e se il modello gestisce adeguatamente la complessit√†.

---

## üìÑ DASHBOARD 4: Analisi per Documento (`paper_analysis.png`)

*Generata solo se ci sono pi√π documenti*

### Grafico 1: Performance per Paper/Documento
- **Scopo**: Confronta la performance del modello su diversi documenti
- **Cosa osservare**:
  - Documenti particolarmente problematici
  - Variabilit√† tra documenti
  - Numero di domande per documento
- **Interpretazione**: Alcuni documenti potrebbero essere pi√π difficili da processare.

### Grafico 2: Variabilit√† Performance per Paper
- **Scopo**: Boxplot della consistenza all'interno di ogni documento
- **Cosa osservare**:
  - Box larghi = alta variabilit√† interna
  - Box stretti = performance consistente
  - Outliers all'interno dei documenti
- **Interpretazione**: Indica se alcuni documenti hanno sezioni pi√π difficili.

---

## üéØ COME UTILIZZARE I GRAFICI

### 1. **Workflow di Analisi Consigliato**:
   1. Inizia con Dashboard 1 per overview generale
   2. Usa Dashboard 2 per analisi dettagliata delle cause
   3. Esamina Dashboard 3 per casi specifici
   4. Se multipli documenti, consulta Dashboard 4

### 2. **Indicatori di Alert**:
   - **üî¥ Alert Rosso**: Similarit√† media < 0.30 in qualsiasi categoria
   - **üü° Alert Giallo**: Similarit√† media < 0.50 in categorie principali  
   - **‚úÖ Target**: Similarit√† media > 0.70 in tutte le categorie
   - **üèÜ Eccellenza**: Similarit√† media > 0.85

### 4. **Pattern da Investigare**:
   - **Correlazione retrieval-performance bassa**: Problema nella generazione
   - **Performance peggiore su difficolt√† alte**: Normale, ma verifica il gap
   - **Argomenti specifici problematici**: Mancanza di knowledge domain
   - **Alta variabilit√†**: Modello inconsistente, serve regularization

### 5. **Azioni Raccomandate per Categoria**:
   - **Retrieval**: Migliorare chunking, embedding, ranking
   - **Generazione**: Ottimizzare prompt, temperatura, max_tokens
   - **Knowledge**: Aggiungere documenti specifici per argomenti deboli
   - **Consistency**: Implementare ensemble methods o post-processing

---

## üìã CHECKLIST DI CONTROLLO QUALIT√Ä

**‚úÖ Sistema Sano**:
- [ ] Similarit√† media > 0.60 (`04_distribuzione_performance.png`)
- [ ] Tasso Buono+ > 50% (verificare nel report)
- [ ] Correlazione retrieval-performance > 0.4 (`05_correlazione_chunk_performance.png`)
- [ ] Nessun argomento con similarit√† < 0.30 (`02_performance_per_argomento.png`)
- [ ] Pochi o zero casi di non-risposta (`09_casi_non_risposta.png`)

**‚ö†Ô∏è Sistema che Necessita Attenzione**:
- [ ] Similarit√† media 0.40-0.60
- [ ] Tasso Buono+ 30-50% 
- [ ] Alcuni argomenti problematici
- [ ] Alta variabilit√† tra documenti (`13_variabilita_per_paper.png`)

**üö® Sistema Critico**:
- [ ] Similarit√† media < 0.40
- [ ] Tasso Buono+ < 30%
- [ ] Molti casi con similarit√† = 0 (`09_casi_non_risposta.png`)
- [ ] Nessuna correlazione retrieval-performance (`05_correlazione_chunk_performance.png`)

---

## üìÅ STRUTTURA FILE GENERATI

```
plots/
‚îú‚îÄ‚îÄ 01_performance_per_difficolta.png      # Performance vs difficolt√†
‚îú‚îÄ‚îÄ 02_performance_per_argomento.png       # Performance per argomento
‚îú‚îÄ‚îÄ 03_heatmap_argomento_difficolta.png    # Interazione difficolt√†-argomento
‚îú‚îÄ‚îÄ 04_distribuzione_performance.png       # Distribuzione generale
‚îú‚îÄ‚îÄ 05_correlazione_chunk_performance.png  # Correlazione retrieval-risposta
‚îú‚îÄ‚îÄ 06_lunghezza_per_qualita.png          # Analisi lunghezza risposte
‚îú‚îÄ‚îÄ 07_performance_per_tipo_domanda.png    # Performance per tipo domanda
‚îú‚îÄ‚îÄ 08_coverage_termini_tecnici.png       # Coverage terminologia
‚îú‚îÄ‚îÄ 09_casi_non_risposta.png              # Fallimenti totali
‚îú‚îÄ‚îÄ 10_peggiori_performance.png           # Peggiori performance effettive
‚îú‚îÄ‚îÄ 11_distribuzione_per_difficolta.png   # Boxplot per difficolt√†
‚îú‚îÄ‚îÄ 12_performance_per_paper.png          # Performance per documento*
‚îî‚îÄ‚îÄ 13_variabilita_per_paper.png          # Variabilit√† per documento*

* = Generati solo con pi√π documenti
```

---

*Documentazione aggiornata per il sistema di analisi RAG con grafici separati*
